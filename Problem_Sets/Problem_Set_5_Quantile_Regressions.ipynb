{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff122141",
   "metadata": {},
   "source": [
    "# Ec 143 - Problem Set 5\n",
    "# Quantile Regression\n",
    "Due by 5PM on April 23rd. The GSI, Nadav Tadelis (ntadelis@berkeley.edu), will handle the logistics of problem set collection.\n",
    "\n",
    "Working with peers on the problem set is actively encouraged, but everyone needs to turn in their own Jupyter Notebook and any other accompanying materials. \n",
    "\n",
    "This problem set reviews the material on quantile regression developed in lecture. Any \"pencil and paper\" and/or narrative answers may be placed in markdown boxes in this Jupyter notebook (preferred). Alternatively you can hand write your answers and turn in a pdf scan of them. This problem set is deliberately more open-ended than the first four and consequently you may find it challenging (but I hope also rewarding).\n",
    "\n",
    "Any computational questions should be answered by writing the required code and executing it. This should be included in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b134d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b0d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '/Users/bgraham/Dropbox/Teaching/Berkeley_Courses/Ec143/Ec143_Spring2023/Datasets/'\n",
    "graphics = '/Users/bgraham/Dropbox/Teaching/Berkeley_Courses/Ec143/Ec143_Spring2023/Graphics/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f5540a",
   "metadata": {},
   "source": [
    "The file brazil_pnad96.out contains 65,801 comma delimited records drawn from the 1996 round of the Brazilian Pesquisas Nacional por Amostra de Domicilos (PNAD96). An overview of education, earnings and inequality in Brazil is provided by Blom et al. (2001). This is the same dataset you used in Problem Set #3.\n",
    "\n",
    "**References**\n",
    "Blom, Andreas, Holm-Nielsen, Lauritz, and Verner, Dorte, \"Education, earnings, and inequality in Brazil, 1982-1998: implications for education policy\", _Peabody Journal of Education_ 76, 3-4 (2001), pp. 180 - 221."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af612433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeInDays</th>\n",
       "      <th>YRSSCH</th>\n",
       "      <th>MONTHLY_EARNINGS</th>\n",
       "      <th>Father_NoSchool</th>\n",
       "      <th>Father_Incomplete1stPrimary</th>\n",
       "      <th>Father_Complete1stPrimary</th>\n",
       "      <th>Father_Incomplete2ndPrimary</th>\n",
       "      <th>Father_Complete2ndPrimary</th>\n",
       "      <th>Father_IncompleteSecondary</th>\n",
       "      <th>Father_CompleteSecondary</th>\n",
       "      <th>...</th>\n",
       "      <th>Mother_NoSchool</th>\n",
       "      <th>Mother_Incomplete1stPrimary</th>\n",
       "      <th>Mother_Complete1stPrimary</th>\n",
       "      <th>Mother_Incomplete2ndPrimary</th>\n",
       "      <th>Mother_Complete2ndPrimary</th>\n",
       "      <th>Mother_IncompleteSecondary</th>\n",
       "      <th>Mother_CompleteSecondary</th>\n",
       "      <th>Mother_IncompleteHigher</th>\n",
       "      <th>Mother_CompleteHigher</th>\n",
       "      <th>Mother_DontKnow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "      <td>55551.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.055054</td>\n",
       "      <td>5.830462</td>\n",
       "      <td>634.184245</td>\n",
       "      <td>0.282569</td>\n",
       "      <td>0.205037</td>\n",
       "      <td>0.139691</td>\n",
       "      <td>0.034311</td>\n",
       "      <td>0.054832</td>\n",
       "      <td>0.051808</td>\n",
       "      <td>0.039531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334125</td>\n",
       "      <td>0.189015</td>\n",
       "      <td>0.136199</td>\n",
       "      <td>0.041493</td>\n",
       "      <td>0.065093</td>\n",
       "      <td>0.032691</td>\n",
       "      <td>0.045148</td>\n",
       "      <td>0.016921</td>\n",
       "      <td>0.054760</td>\n",
       "      <td>0.084553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.262022</td>\n",
       "      <td>4.217958</td>\n",
       "      <td>1104.788945</td>\n",
       "      <td>0.450253</td>\n",
       "      <td>0.403732</td>\n",
       "      <td>0.346670</td>\n",
       "      <td>0.182028</td>\n",
       "      <td>0.227655</td>\n",
       "      <td>0.221642</td>\n",
       "      <td>0.194857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471688</td>\n",
       "      <td>0.391524</td>\n",
       "      <td>0.343003</td>\n",
       "      <td>0.199430</td>\n",
       "      <td>0.246693</td>\n",
       "      <td>0.177827</td>\n",
       "      <td>0.207630</td>\n",
       "      <td>0.128978</td>\n",
       "      <td>0.227514</td>\n",
       "      <td>0.278218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.607800</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.188910</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.681720</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          AgeInDays        YRSSCH  MONTHLY_EARNINGS  Father_NoSchool  \\\n",
       "count  55551.000000  55551.000000      55551.000000     55551.000000   \n",
       "mean      37.055054      5.830462        634.184245         0.282569   \n",
       "std       10.262022      4.217958       1104.788945         0.450253   \n",
       "min       20.000000      0.000000          4.000000         0.000000   \n",
       "25%       28.607800      3.000000        180.000000         0.000000   \n",
       "50%       36.188910      5.000000        320.000000         0.000000   \n",
       "75%       44.681720      8.000000        602.000000         1.000000   \n",
       "max       60.000000     15.000000      50000.000000         1.000000   \n",
       "\n",
       "       Father_Incomplete1stPrimary  Father_Complete1stPrimary  \\\n",
       "count                 55551.000000               55551.000000   \n",
       "mean                      0.205037                   0.139691   \n",
       "std                       0.403732                   0.346670   \n",
       "min                       0.000000                   0.000000   \n",
       "25%                       0.000000                   0.000000   \n",
       "50%                       0.000000                   0.000000   \n",
       "75%                       0.000000                   0.000000   \n",
       "max                       1.000000                   1.000000   \n",
       "\n",
       "       Father_Incomplete2ndPrimary  Father_Complete2ndPrimary  \\\n",
       "count                 55551.000000               55551.000000   \n",
       "mean                      0.034311                   0.054832   \n",
       "std                       0.182028                   0.227655   \n",
       "min                       0.000000                   0.000000   \n",
       "25%                       0.000000                   0.000000   \n",
       "50%                       0.000000                   0.000000   \n",
       "75%                       0.000000                   0.000000   \n",
       "max                       1.000000                   1.000000   \n",
       "\n",
       "       Father_IncompleteSecondary  Father_CompleteSecondary  ...  \\\n",
       "count                55551.000000              55551.000000  ...   \n",
       "mean                     0.051808                  0.039531  ...   \n",
       "std                      0.221642                  0.194857  ...   \n",
       "min                      0.000000                  0.000000  ...   \n",
       "25%                      0.000000                  0.000000  ...   \n",
       "50%                      0.000000                  0.000000  ...   \n",
       "75%                      0.000000                  0.000000  ...   \n",
       "max                      1.000000                  1.000000  ...   \n",
       "\n",
       "       Mother_NoSchool  Mother_Incomplete1stPrimary  \\\n",
       "count     55551.000000                 55551.000000   \n",
       "mean          0.334125                     0.189015   \n",
       "std           0.471688                     0.391524   \n",
       "min           0.000000                     0.000000   \n",
       "25%           0.000000                     0.000000   \n",
       "50%           0.000000                     0.000000   \n",
       "75%           1.000000                     0.000000   \n",
       "max           1.000000                     1.000000   \n",
       "\n",
       "       Mother_Complete1stPrimary  Mother_Incomplete2ndPrimary  \\\n",
       "count               55551.000000                 55551.000000   \n",
       "mean                    0.136199                     0.041493   \n",
       "std                     0.343003                     0.199430   \n",
       "min                     0.000000                     0.000000   \n",
       "25%                     0.000000                     0.000000   \n",
       "50%                     0.000000                     0.000000   \n",
       "75%                     0.000000                     0.000000   \n",
       "max                     1.000000                     1.000000   \n",
       "\n",
       "       Mother_Complete2ndPrimary  Mother_IncompleteSecondary  \\\n",
       "count               55551.000000                55551.000000   \n",
       "mean                    0.065093                    0.032691   \n",
       "std                     0.246693                    0.177827   \n",
       "min                     0.000000                    0.000000   \n",
       "25%                     0.000000                    0.000000   \n",
       "50%                     0.000000                    0.000000   \n",
       "75%                     0.000000                    0.000000   \n",
       "max                     1.000000                    1.000000   \n",
       "\n",
       "       Mother_CompleteSecondary  Mother_IncompleteHigher  \\\n",
       "count              55551.000000             55551.000000   \n",
       "mean                   0.045148                 0.016921   \n",
       "std                    0.207630                 0.128978   \n",
       "min                    0.000000                 0.000000   \n",
       "25%                    0.000000                 0.000000   \n",
       "50%                    0.000000                 0.000000   \n",
       "75%                    0.000000                 0.000000   \n",
       "max                    1.000000                 1.000000   \n",
       "\n",
       "       Mother_CompleteHigher  Mother_DontKnow  \n",
       "count           55551.000000     55551.000000  \n",
       "mean                0.054760         0.084553  \n",
       "std                 0.227514         0.278218  \n",
       "min                 0.000000         0.000000  \n",
       "25%                 0.000000         0.000000  \n",
       "50%                 0.000000         0.000000  \n",
       "75%                 0.000000         0.000000  \n",
       "max                 1.000000         1.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnad96 = pd.read_csv(data + 'Brazil_1996PNAD.out', header = 0, sep='\\t+', engine='python')\n",
    "\n",
    "# Find relevant estimation subsample\n",
    "sample = pnad96.loc[(pnad96['MONTHLY_EARNINGS'] > 0) & (pnad96['AgeInDays'] >= 20)  & (pnad96['AgeInDays'] <= 60)]\n",
    "\n",
    "#Display the first few rows of the dataframe\n",
    "sample.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b96e896",
   "metadata": {},
   "source": [
    "## Warm-Up ##\n",
    "\n",
    "1. Compute the least squares fit of ln(MONTHLY_EARNINGS) onto a constant YRSSCH, AgeInDays, and AgeInDays squared.   \n",
    "\n",
    "2. Create a dummy variable for each of the $16$ possible schooling levels. Compute the least squares fit of ln(MONTHLY_EARNINGS) onto each of the $16$ dummy variables, AgeInDays, and AgeInDays squared (exclude a constant from this regression).    \n",
    "\n",
    "3. Construct a plot with the regression fits from parts (1) and (2) above on the same same figure holding AgeInDays fixed at $40$, but varying YRSSCH. Comment on your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45b94fe",
   "metadata": {},
   "source": [
    "## Exploring the conditional distribution of earnings given schooling ##\n",
    "\n",
    "In this part of the problem set you will explore the conditional distribution of earnings given schooling and age using quantile regression. There are a variety of ways to undertake the computations described below. Tools you may need include a \"for loop\", a Pandas dataframe for organizing your results and setting up your regressor matrix, the numpy.quantile and numpy.sort (to find order statistics) will be useful for find quantile point estimates and constructing standard errors. To construct standard errors for your minimum distance estimates you will need to do some basic matrix multiplication. This is best done using Numpy.\n",
    "\n",
    "4. Construct two histograms; one each for the distribution of the logarithm of monthly earnings given YRSSCH = 0 and another YRSSCH = 8. Comment on any differences.\n",
    "\n",
    "5. Consider the following $L=8$ age ranges: $\\left[20,25\\right),\\left[25,30\\right),\\left[30,35\\right),\\left[35,40\\right),\\left[40,45\\right),\\left[45,50\\right),\\left[50,55\\right),\\left[55,60\\right]$. Let $K=16$ be the number of distinct schooling values. For each of the $K\\times L=8\\times16=128$ years of schooling and age range combinations with at least $30$ observations in the dataset estimate the 10th, 25th, 50th, 75th and 90th quantiles of the distribution of log earnings. For each conditional quantile construct a confidence interval using order statistics as described in lecture. Using this confidence interval construct an asymptotic variance estimate.     \n",
    "\n",
    "6. Inspect your standard error estimates. Are any of them are zero? Why? Inspect the distribution of MONTHLY_EARNINGS. Is MONTHLY_EARNINGS a continuously-valued random variable? Relate what you find to the phenomena of standard error estimates of zero [1 paragraph].    \n",
    "\n",
    "7. Assume that, for the five estimated quantiles, the conditional quantile function of the logarithm of monthly earnings given schooling and age is a linear function of YRSSCH, AgeInDays, and AgeInDays squared (you may use the mid-point of each of the age ranges as your measure of “age”). Estimate the parameters indexing each of the five conditional quantile functions by minimum distance as described in lecture. You should exclude all cells with less that 30 observations and/or where the estimated standard error is zero. How does the coefficient on schooling vary with the quantile under consideration? How does it compare to that computed in question (2) above?\n",
    "\n",
    "8. Summarize, in words, your analysis. How do earnings vary with education in Brazil? [4 to 6 paragraphs]\n",
    "\n",
    "9. Repeat your analysis in part (7) for all “centiles” 5,6,7....,94,95. Plot “centile” on the x-axis and the corresponding coefficient on schooling on the y-axis. Also plot the corresponding point-wise 95 percent confidence band. Comment on your graph [1 to 3 paragraphs]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51988a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
